# A/B-тестирование: постановка и анализ

## 1) Постановка A/B-теста (чек-лист)
1. **Цель и гипотеза**
   - Что именно мы проверяем?
   - Какое ожидаемое влияние на метрику?

2. **Ключевая метрика**
   - Какая метрика будет основной для оценки?
   - Дополнительная метрика — чтобы убедиться, что нет побочного эффекта.

3. **Базовый уровень метрики**
   - Нужно знать текущие значения (baseline).

4. **Минимальный детектируемый эффект (MDE)**
   - Какая разница для бизнеса считается «значимой»?

5. **Уровень значимости и мощность теста**
   - **α** — уровень значимости, допустимый риск ложноположительного вывода (обычно 0.05).
   - **β** — риск пропустить эффект (обычно 0.2 → мощность = 1−β = 80%).

---

## 2) Дизайн эксперимента и статистика

### 2.1 Расчёт выборки
Сколько пользователей нужно в каждой группе, чтобы увидеть **MDE**.

### 2.2 Какие тесты используют?

#### Для бинарных метрик (CTR, конверсия)
- **z-test пропорций** — популярный при больших выборках.  
- **χ²-test** — альтернатива, особенно при нескольких категориях.  
- **Fisher’s exact test** — при маленьких выборках (ожидаемые частоты < 5).

#### Для средних метрик (средний чек, ARPU, время сессии)
- **t-test Стьюдента** — сравнение средних.  
- **Welch’s t-test** — если дисперсии в группах различаются.

#### Непараметрический случай
- **Mann–Whitney U** — когда распределение сильно скошено/ненормально или выборки малы.

#### Более чем 2 группы
- **ANOVA** — сравнение средних в нескольких группах.

### 2.3 P-value и корректировки

**Что такое p-value?**  
Это не вероятность того, что нулевая гипотеза верна; это мера совместимости наблюдаемых данных с нулевой гипотезой.

**Коррекция множественных гипотез** (чтобы снизить риск ложноположительных результатов при проверке многих метрик):
- **Bonferroni**: новая граница \(\alpha_{new} = \alpha / m\).  
  *Пример:* 5 метрик, \(\alpha=0.05\) → \(\alpha_{new}=0.01\). Значимы результаты с \(p \le 0.01\).
- **Benjamini–Hochberg (BH)**:  
  1) Отсортируйте p-values по возрастанию (напр., 0.01, 0.02, 0.04, 0.15, 0.20).  
  2) Сравните каждый \(p_i\) с \((i/m)\cdot\alpha\).  
  *Пример:* \(\alpha=0.05\), \(m=5\) → границы 0.01, 0.02, 0.03, 0.04, 0.05.  
  Значимыми окажутся, например, **Retention (0.01)** и **CTR (0.02)**.

### 2.4 Центральная предельная теорема (ЦПТ)
При больших выборках распределение средней метрики стремится к нормальному, даже если исходное распределение не нормальное — это обосновывает применение t-тестов и построение доверительных интервалов.

---

# Ошибки I и II рода

## Ошибка I рода (ложноположительная)
Отклоняется верная нулевая гипотеза, которая утверждает, что никаких различий нет.

## Ошибка II рода (ложноотрицательная)
Не отклоняется ложная нулевая гипотеза.  
Другими словами, тест не смог увидеть реальное улучшение.


# Мощность теста
Мощность теста — это чувствительность теста.
 
Мощность теста=1 − вероятность ошибки II рода (β)



## 2.3 P-value и корректировки

### Что такое p-value?
Это не вероятность того, что нулевая гипотеза верна;  
p-value — это мера совместимости наблюдаемых данных с нулевой гипотезой.

---

### Коррекция множественных гипотез
Чтобы снизить риск ложноположительных результатов при проверке многих метрик, используют корректировки.

#### 1. Поправка Бонферрони
Новая граница:

\[
\alpha_{new} = \frac{\alpha}{m}
\]

- **Пример:** 5 метрик, \(\alpha = 0.05\)  
  → \(\alpha_{new} = 0.01\).  
  Значимыми считаются только результаты с \(p \leq 0.01\).

---

#### 2. Метод Бенджамини–Хохберга (Benjamini–Hochberg, BH)

1. Отсортируйте p-values по возрастанию (например: 0.01, 0.02, 0.04, 0.15, 0.20).  
2. Сравните каждый \(p_i\) с \(\frac{i}{m} \cdot \alpha\).  

- **Пример:** \(\alpha = 0.05\), \(m = 5\).  
  → границы: 0.01, 0.02, 0.03, 0.04, 0.05.  

Значимыми окажутся, например:  
- **Retention = 0.01**  
- **CTR = 0.02**

